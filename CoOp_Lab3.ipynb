{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36d4628726ade6e1",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Exercise 3.2: Fine-tuning a CLIP Model (harder)\n",
    "\n",
    "Use a (small) CLIP model like [`openai/clip-vit-base-patch16`](https://huggingface.co/openai/clip-vit-base-patch16) and evaluate its zero-shot performance on a small image classification dataset like ImageNette or TinyImageNet. Fine-tune (using a parameter-efficient method!) the CLIP model to see how much improvement you can squeeze out of it.\n",
    "\n",
    "**Note**: There are several ways to adapt the CLIP model; you could fine-tune the image encoder, the text encoder, or both. Or, you could experiment with prompt learning.\n",
    "\n",
    "**Tip**: CLIP probably already works very well on ImageNet and ImageNet-like images. For extra fun, look for an image classification dataset with different image types (e.g. *sketches*)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81eb811727fa9833",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# CoOp\n",
    "leggendo la richiesta sopra mi sono subito interessato all prompt learaning, in particolare al metodo [`CoOp`](https://arxiv.org/pdf/2109.01134) ho iniziato verificando come il modello genera le text features. Ho confrontato le embedding testuali ottenute in modo standard con quelle calcolate manualmente, ricostruendo passo passo l'intero flusso: partendo dagli embedding di token e posizione, passando per l'encoder transformer con la casual attention mask, applicando la layer norm finale e selezionando il token [EOT], fino alla proiezione lineare conclusiva. Il confronto ha mostrato che le text features manuali sono identiche a quelle standard, così come i logits ottenuti dal prodotto scalare con le image features. Questa verifica è fondamentale per poter in seguito sostituire gli embedding statici con quelli apprendibili, come previsto dal metodo CoOp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2025-07-02T14:37:51.203341200Z",
     "start_time": "2025-07-02T14:37:35.810341700Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gli embending sono uguali : True\n",
      "l'uscita dell'encoder è uguale : 12\n",
      "features sono uguali : True\n",
      "--- VERIFICA DEI RISULTATI FINALI (LOGITS) ---\n",
      "Logits calcolati con metodo STANDARD: [[22.73867  15.661786]]\n",
      "Logits calcolati con metodo MANUALE:  [[22.738672 15.661789]]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "import requests\n",
    "from transformers import CLIPProcessor, CLIPModel\n",
    "from transformers.modeling_attn_mask_utils import _create_4d_causal_attention_mask\n",
    "\n",
    "model_name = \"openai/clip-vit-base-patch16\"\n",
    "model = CLIPModel.from_pretrained(model_name).eval()\n",
    "processor = CLIPProcessor.from_pretrained(model_name)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model.to(device)\n",
    "\n",
    "\n",
    "texts = [\"a photo of a cat\", \"a photo of a dog\"]\n",
    "inputs = processor(text=texts, return_tensors=\"pt\", padding=True).to(device)\n",
    "url = \"http://images.cocodataset.org/val2017/000000039769.jpg\"\n",
    "image = Image.open(requests.get(url, stream=True).raw)\n",
    "\n",
    "input_ids = inputs['input_ids']\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    \n",
    "    outputs = model.text_model(**inputs, output_hidden_states=True)\n",
    "    standard_text_features = model.get_text_features(input_ids=input_ids)\n",
    "\n",
    "\n",
    "    embeddings_module = model.text_model.embeddings\n",
    "    token_embeds = embeddings_module.token_embedding(input_ids)\n",
    "    position_ids = torch.arange(input_ids.shape[1], device=device).unsqueeze(0)\n",
    "    positional_embeds = embeddings_module.position_embedding(position_ids)\n",
    "    manual_initial_embeddings = token_embeds + positional_embeds\n",
    "    \n",
    "    print(\"gli embending sono uguali :\", manual_initial_embeddings.equal(outputs.hidden_states[0]))\n",
    "   \n",
    "    causal_attention_mask = _create_4d_causal_attention_mask(\n",
    "        input_ids.size(), manual_initial_embeddings.dtype, device=device\n",
    "    )  \n",
    "    encoder_outputs = model.text_model.encoder(inputs_embeds=manual_initial_embeddings, output_hidden_states=True , causal_attention_mask=causal_attention_mask)\n",
    "    i = 0 \n",
    "    for hidden in outputs.hidden_states:\n",
    "        if encoder_outputs.last_hidden_state.equal(hidden):\n",
    "            print(\"l'uscita dell'encoder è uguale :\", i)\n",
    "        i+=1\n",
    "        \n",
    "    standard_text_features = model.get_text_features(input_ids=input_ids, output_hidden_states=True )\n",
    "  \n",
    "    last_hidden_state = encoder_outputs.last_hidden_state\n",
    "    normed_hidden_state = model.text_model.final_layer_norm(last_hidden_state)\n",
    "    eot_token_positions = torch.argmax(input_ids, dim=-1)\n",
    "    pooled_output = normed_hidden_state[torch.arange(normed_hidden_state.shape[0], device=device), eot_token_positions]\n",
    "    manual_text_features = model.text_projection(pooled_output)\n",
    "    print(\"features sono uguali :\",standard_text_features.equal(manual_text_features))\n",
    "   \n",
    "   \n",
    "    image_inputs = processor(images=image, return_tensors=\"pt\").to(device)\n",
    "    image_features = model.get_image_features(**image_inputs)\n",
    "    \n",
    "    image_features_norm = image_features / image_features.norm(p=2, dim=-1, keepdim=True)\n",
    "    logit_scale = model.logit_scale.exp()\n",
    "    \n",
    "    text_features_norm_man = manual_text_features / manual_text_features.norm(p=2, dim=-1, keepdim=True)\n",
    "    logits_manual = logit_scale * image_features_norm @ text_features_norm_man.t()\n",
    "\n",
    "    \n",
    "     \n",
    "    inputs_image_text = processor(text=texts, images=image, return_tensors=\"pt\", padding=True).to(device)\n",
    "    standard_outputs = model(**inputs_image_text)\n",
    "    logits_standard = standard_outputs.logits_per_image\n",
    "    probs_standard = logits_standard.softmax(dim=-1)\n",
    "        \n",
    "    print(\"--- VERIFICA DEI RISULTATI FINALI (LOGITS) ---\")\n",
    "    print(\"Logits calcolati con metodo STANDARD:\", logits_standard.cpu().numpy())\n",
    "    print(\"Logits calcolati con metodo MANUALE: \", logits_manual.cpu().numpy())\n",
    "    \n",
    "   \n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c033b6078062f0",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Fine-tuning CLIP con CoOp\n",
    "definiamo un nuovo modello ovvero CLIP con il CoOp\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4972776f8329c8dc",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-07-02T14:37:51.217340300Z",
     "start_time": "2025-07-02T14:37:51.209341100Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import CLIPProcessor, CLIPModel, CLIPTokenizer\n",
    "from transformers.modeling_attn_mask_utils import _create_4d_causal_attention_mask\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "MODEL_NAME = \"openai/clip-vit-base-patch16\"\n",
    "\n",
    "class CoOpCLIP(nn.Module):\n",
    "    def __init__(self, class_names, clip_model, m_ctx=16):\n",
    "        super().__init__()\n",
    "        self.class_names = class_names\n",
    "        self.n_classes = len(class_names)\n",
    "        self.n_ctx = m_ctx\n",
    "        self.clip_model = clip_model\n",
    "        embedding_dim = clip_model.text_model.config.hidden_size\n",
    "        ctx_vectors = torch.empty(self.n_ctx, embedding_dim, device=DEVICE)\n",
    "        nn.init.normal_(ctx_vectors, std=0.02)\n",
    "        self.context_vectors = nn.Parameter(ctx_vectors)\n",
    "        self.tokenizer = CLIPTokenizer.from_pretrained(MODEL_NAME)\n",
    "        tokenized_classes = self.tokenizer([c for c in class_names], padding = True, return_tensors=\"pt\")\n",
    "        self.class_token_ids = tokenized_classes.input_ids.to(DEVICE)\n",
    "        for param in self.clip_model.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "    def construct_prompts(self):\n",
    "        embedding_layer = self.clip_model.text_model.embeddings.token_embedding\n",
    "        prefix_embeddings = embedding_layer(self.class_token_ids[:, :1])\n",
    "        class_embeddings = embedding_layer(self.class_token_ids[:, 1:])\n",
    "        context_embeddings = self.context_vectors.unsqueeze(0).expand(self.n_classes, -1, -1)\n",
    "        prompt_embeddings = torch.cat([prefix_embeddings, context_embeddings, class_embeddings], dim=1)\n",
    "        return prompt_embeddings\n",
    "\n",
    "    def forward(self, image):\n",
    "       \n",
    "\n",
    "        prompt_embeds = self.construct_prompts()\n",
    "        \n",
    "        text_encoder = self.clip_model.text_model\n",
    "        # print(prompt_embeds.shape, prompt_embeds.dtype, prompt_embeds.device)\n",
    "        pos_ids = torch.arange(prompt_embeds.size(1), device=DEVICE).unsqueeze(0)\n",
    "        positional_embeddings = text_encoder.embeddings.position_embedding(pos_ids)\n",
    "        inputs_embeds = prompt_embeds + positional_embeddings\n",
    "        \n",
    "        input_shape = prompt_embeds.shape[:2]\n",
    "        \n",
    "        # per utilizzare correttamente l'encoder è fondamentale creare una maschera di attenzione causale ho seguito l'implementazione a \n",
    "        # https://github.com/huggingface/transformers/blob/main/src/transformers/models/clip/modeling_clip.py#L620 \n",
    "        # riga 620 gli ho passato la dimensione degli input_ids con anche gli embedding aggiunti  [102 , 1+16+7] prefisso context class ed end \n",
    "        causal_attention_mask = _create_4d_causal_attention_mask(\n",
    "            input_shape, inputs_embeds.dtype, device=DEVICE\n",
    "        )\n",
    "\n",
    "        encoder_outputs = text_encoder.encoder(\n",
    "            inputs_embeds=inputs_embeds,\n",
    "            causal_attention_mask=causal_attention_mask\n",
    "        )\n",
    "        last_hidden_state = encoder_outputs.last_hidden_state\n",
    "\n",
    "        eos_positions = self.class_token_ids.argmax(dim=-1) \n",
    "        # print(eos_positions)\n",
    "        final_token_indices = self.n_ctx + (eos_positions)\n",
    "        #https://github.com/huggingface/transformers/blob/main/src/transformers/models/clip/modeling_clip.py#L1023 \n",
    "        #ripreso da 1023 a 1035\n",
    "        pooled_output = last_hidden_state[torch.arange(self.n_classes), final_token_indices]\n",
    " \n",
    "        pooled_output = text_encoder.final_layer_norm(pooled_output)\n",
    "        \n",
    "        \n",
    "        \n",
    "        image_features = self.clip_model.get_image_features(pixel_values=image)\n",
    "        image_features = image_features / image_features.norm(p=2,dim=-1, keepdim=True)\n",
    "        \n",
    "        text_features = self.clip_model.text_projection(pooled_output)\n",
    "        text_features = text_features / text_features.norm(p=2, dim=-1, keepdim=True) # implementazione in una riga di vector norm \n",
    "        \n",
    "        logit_scale = self.clip_model.logit_scale.exp()\n",
    "       \n",
    "        logits = logit_scale * image_features @ text_features.t()\n",
    "        #al posto di mat mul ho usato @ \n",
    "\n",
    "        return logits\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e66b196a1d379934",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# few shot learning\n",
    "definamo la funzione per la creazione di un dataset few shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ca97e78ad379757",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-07-02T14:37:51.238340800Z",
     "start_time": "2025-07-02T14:37:51.219339700Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "class FewShotDataset(Dataset):\n",
    "    def __init__(self, samples):\n",
    "        self.samples = samples\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    def __getitem__(self, idx):\n",
    "        return self.samples[idx]\n",
    "    \n",
    "    \n",
    "def create_few_shot_split(full_dataset, num_shots):\n",
    "    if num_shots > 10:\n",
    "        raise ValueError(\"Il numero di campioni per classe deve essere <= 10\")\n",
    "    \n",
    "    samples_per_class = {i: [] for i in range(len(class_names))}\n",
    "    for idx, (_, label) in enumerate(full_dataset):\n",
    "        samples_per_class[label].append(idx)\n",
    "    few_shot_samples = []\n",
    "    #print(samples_per_class)\n",
    "    for label, indices in samples_per_class.items():\n",
    "        selected_indices = random.sample(indices, min(num_shots, len(indices)))\n",
    "        for idx in selected_indices:\n",
    "            few_shot_samples.append(full_dataset[idx])\n",
    "    return FewShotDataset(few_shot_samples)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10c864db65ced403",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Accuracy\n",
    "definamo una la funzione evaluate per calcolare l'accuratezza del Clip base (Zero Shot) e del CoOp dato che hanno interfaccie diverse usato un parametro zero shot per distinguere i due casi "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3dc1a12a056a4a7",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-07-02T14:37:51.726341500Z",
     "start_time": "2025-07-02T14:37:51.231341600Z"
    }
   },
   "outputs": [],
   "source": [
    "import evaluate as hfevaluate\n",
    "from tqdm.notebook import tqdm\n",
    "@torch.no_grad()\n",
    "def evaluate(model, dataloader, processor, class_names, is_zeroshot=False):\n",
    "    model.eval()\n",
    "    accuracy_metric = hfevaluate.load(\"accuracy\")\n",
    "    if is_zeroshot:\n",
    "        text_inputs = processor(\n",
    "            text=[f\"a photo of a {c}, a type of flower.\" for c in class_names],  #da fig 1 pag 2 si osserva che si ottiene risultati migliori \n",
    "            return_tensors=\"pt\", padding=True\n",
    "        ).to(DEVICE)\n",
    "        text_features = model.get_text_features(**text_inputs)\n",
    "        text_features /= text_features.norm(p=2, dim=-1, keepdim=True)\n",
    "\n",
    "    pbar = tqdm(dataloader, desc=\"Valutazione\")\n",
    "    for images, labels in pbar:\n",
    "        images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "        \n",
    "        if is_zeroshot:\n",
    "            image_features = model.get_image_features(pixel_values=images)\n",
    "            image_features /= image_features.norm(p=2, dim=-1, keepdim=True)\n",
    "            logits = model.logit_scale.exp() * image_features @ text_features.t()\n",
    "        else: \n",
    "            logits = model(images)\n",
    "\n",
    "        predictions = torch.argmax(logits, dim=-1)\n",
    "        \n",
    "        accuracy_metric.add_batch(predictions=predictions, references=labels)\n",
    "    results = accuracy_metric.compute()\n",
    "    return results['accuracy'] * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7233ae04bf9f3d64",
   "metadata": {
    "collapsed": false
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9c2a48f0a070918c",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Train and Evaluate\n",
    "implemento la logica per addestrare e valutare il modello con CoOp ho scelto come dataset flower102 ogni 10 epoche valuto sul validation set e salvo il modello migliore, alla fine valuto sul test set e calcolo la differenza con il modello zero shot. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "532fb316698316e2",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-07-02T16:28:43.159918600Z",
     "start_time": "2025-07-02T14:37:51.730340100Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 345M/345M [00:28<00:00, 12.1MB/s] \n",
      "100%|██████████| 502/502 [00:00<00:00, 504kB/s]\n",
      "100%|██████████| 15.0k/15.0k [00:00<00:00, 15.0MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caricato il dataset Flowers102 con 1020 immagini di addestramento, 6149 immagini di test e 1020 immagini di validazione.\n",
      "\n",
      "--- Calcolo della Baseline Zero-Shot CLIP ---\n"
     ]
    },
    {
     "data": {
      "text/plain": "Valutazione:   0%|          | 0/193 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "040fe045f4324648a382c8eefe0819ea"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Zero-Shot CLIP: 71.30%\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Addestramento CoOp con 1 shot per classe ---\n"
     ]
    },
    {
     "data": {
      "text/plain": "Addestramento CoOp (1-shot):   0%|          | 0/50 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "cd6357dc1cf6478c887e6056744c7a58"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Valutazione:   0%|          | 0/32 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "489ecc3e367e44bfb19e61b889315c83"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/50, Loss: 0.4364\n",
      "Validation Accuracy: 78.63%\n",
      " Nuovo modello migliore salvato in 'best_models/best_coop_1-shot.pth' con accuracy 78.63%\n"
     ]
    },
    {
     "data": {
      "text/plain": "Valutazione:   0%|          | 0/32 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f8f48e486c8e474a9580610623d04482"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/50, Loss: 0.0913\n",
      "Validation Accuracy: 79.41%\n",
      " Nuovo modello migliore salvato in 'best_models/best_coop_1-shot.pth' con accuracy 79.41%\n"
     ]
    },
    {
     "data": {
      "text/plain": "Valutazione:   0%|          | 0/32 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0ad00d50598b449fbb3419cc26f43540"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/50, Loss: 0.0520\n",
      "Validation Accuracy: 79.31%\n"
     ]
    },
    {
     "data": {
      "text/plain": "Valutazione:   0%|          | 0/32 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "56fe89e8d12347fea5a75d2dc4b3c8ee"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/50, Loss: 0.0415\n",
      "Validation Accuracy: 78.73%\n"
     ]
    },
    {
     "data": {
      "text/plain": "Valutazione:   0%|          | 0/32 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5d93a26e29a94a70b08b5a3de3f910b1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50, Loss: 0.0393\n",
      "Validation Accuracy: 78.43%\n"
     ]
    },
    {
     "data": {
      "text/plain": "Valutazione:   0%|          | 0/193 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "868a7178eafd4fc6aa2ca8ca40b59b55"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy CoOp (1-shot) sul TEST SET: 77.69%\n",
      "Differenza vs Zero-Shot: +6.39%\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Addestramento CoOp con 2 shot per classe ---\n"
     ]
    },
    {
     "data": {
      "text/plain": "Addestramento CoOp (2-shot):   0%|          | 0/100 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b5618057b791476d81d6e710d49ecd2b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Valutazione:   0%|          | 0/32 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ad28fce473a4403a9e412dc2b6281914"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/100, Loss: 0.2669\n",
      "Validation Accuracy: 87.25%\n",
      " Nuovo modello migliore salvato in 'best_models/best_coop_2-shot.pth' con accuracy 87.25%\n"
     ]
    },
    {
     "data": {
      "text/plain": "Valutazione:   0%|          | 0/32 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f3e9fc8d662a4b6da7e202960421a846"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/100, Loss: 0.0503\n",
      "Validation Accuracy: 88.33%\n",
      " Nuovo modello migliore salvato in 'best_models/best_coop_2-shot.pth' con accuracy 88.33%\n"
     ]
    },
    {
     "data": {
      "text/plain": "Valutazione:   0%|          | 0/32 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "016a3edfd958434ab7431cd4ea923706"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/100, Loss: 0.0281\n",
      "Validation Accuracy: 88.24%\n"
     ]
    },
    {
     "data": {
      "text/plain": "Valutazione:   0%|          | 0/32 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "371d30465eeb4ba6a8fc06b7952b0352"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/100, Loss: 0.0204\n",
      "Validation Accuracy: 88.73%\n",
      " Nuovo modello migliore salvato in 'best_models/best_coop_2-shot.pth' con accuracy 88.73%\n"
     ]
    },
    {
     "data": {
      "text/plain": "Valutazione:   0%|          | 0/32 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "cc99a40b50f5422f9d4169e4f89e1aa6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/100, Loss: 0.0166\n",
      "Validation Accuracy: 88.92%\n",
      " Nuovo modello migliore salvato in 'best_models/best_coop_2-shot.pth' con accuracy 88.92%\n"
     ]
    },
    {
     "data": {
      "text/plain": "Valutazione:   0%|          | 0/32 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ed1fe2322de34d57bb7c54ddf99ec86b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/100, Loss: 0.0145\n",
      "Validation Accuracy: 88.73%\n"
     ]
    },
    {
     "data": {
      "text/plain": "Valutazione:   0%|          | 0/32 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ba1613d773e2492bbba6d6d28bfb00b7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70/100, Loss: 0.0133\n",
      "Validation Accuracy: 88.63%\n"
     ]
    },
    {
     "data": {
      "text/plain": "Valutazione:   0%|          | 0/32 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "02e9f9cb809e4a1ba0172fc818a3dfb8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/100, Loss: 0.0127\n",
      "Validation Accuracy: 88.63%\n"
     ]
    },
    {
     "data": {
      "text/plain": "Valutazione:   0%|          | 0/32 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "67ab9917ac4f4fe3b44cbc67409c4e42"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90/100, Loss: 0.0124\n",
      "Validation Accuracy: 88.73%\n"
     ]
    },
    {
     "data": {
      "text/plain": "Valutazione:   0%|          | 0/32 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "61b0f4349a714c088a2a7ff51d5497fe"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/100, Loss: 0.0123\n",
      "Validation Accuracy: 88.73%\n"
     ]
    },
    {
     "data": {
      "text/plain": "Valutazione:   0%|          | 0/193 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e497fbbd2e224fa0b92eae716eb10864"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy CoOp (2-shot) sul TEST SET: 89.40%\n",
      "Differenza vs Zero-Shot: +18.10%\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Addestramento CoOp con 4 shot per classe ---\n"
     ]
    },
    {
     "data": {
      "text/plain": "Addestramento CoOp (4-shot):   0%|          | 0/100 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "cc3a43eb6dd541159e4c235987f96336"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Valutazione:   0%|          | 0/32 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6afdf976f5e6487b9b7d6ae04c4e8a47"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/100, Loss: 0.1667\n",
      "Validation Accuracy: 90.69%\n",
      " Nuovo modello migliore salvato in 'best_models/best_coop_4-shot.pth' con accuracy 90.69%\n"
     ]
    },
    {
     "data": {
      "text/plain": "Valutazione:   0%|          | 0/32 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5718476c087c4749b9ce9349404e410e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/100, Loss: 0.0489\n",
      "Validation Accuracy: 90.39%\n"
     ]
    },
    {
     "data": {
      "text/plain": "Valutazione:   0%|          | 0/32 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "60868e49f1714f38ae8d564925a270bd"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/100, Loss: 0.0295\n",
      "Validation Accuracy: 90.98%\n",
      " Nuovo modello migliore salvato in 'best_models/best_coop_4-shot.pth' con accuracy 90.98%\n"
     ]
    },
    {
     "data": {
      "text/plain": "Valutazione:   0%|          | 0/32 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "30ffaf8598ba46f89057c149021d7674"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/100, Loss: 0.0221\n",
      "Validation Accuracy: 91.76%\n",
      " Nuovo modello migliore salvato in 'best_models/best_coop_4-shot.pth' con accuracy 91.76%\n"
     ]
    },
    {
     "data": {
      "text/plain": "Valutazione:   0%|          | 0/32 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c50c88a9fc044a4bac466365424fe419"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/100, Loss: 0.0183\n",
      "Validation Accuracy: 91.76%\n"
     ]
    },
    {
     "data": {
      "text/plain": "Valutazione:   0%|          | 0/32 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "203e156fbc2940908c0a731c52b353ad"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/100, Loss: 0.0161\n",
      "Validation Accuracy: 91.86%\n",
      " Nuovo modello migliore salvato in 'best_models/best_coop_4-shot.pth' con accuracy 91.86%\n"
     ]
    },
    {
     "data": {
      "text/plain": "Valutazione:   0%|          | 0/32 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6c875057cd5747118624c0b972f3457b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70/100, Loss: 0.0147\n",
      "Validation Accuracy: 92.16%\n",
      " Nuovo modello migliore salvato in 'best_models/best_coop_4-shot.pth' con accuracy 92.16%\n"
     ]
    },
    {
     "data": {
      "text/plain": "Valutazione:   0%|          | 0/32 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "39402ffb6c2040ab850e4f23e0c48a44"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/100, Loss: 0.0140\n",
      "Validation Accuracy: 92.25%\n",
      " Nuovo modello migliore salvato in 'best_models/best_coop_4-shot.pth' con accuracy 92.25%\n"
     ]
    },
    {
     "data": {
      "text/plain": "Valutazione:   0%|          | 0/32 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c7dcb6bf18f34a73b901be733445b2fb"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90/100, Loss: 0.0136\n",
      "Validation Accuracy: 92.25%\n"
     ]
    },
    {
     "data": {
      "text/plain": "Valutazione:   0%|          | 0/32 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "48e0f2c5fa124b6c88536beafabd8c04"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/100, Loss: 0.0136\n",
      "Validation Accuracy: 92.25%\n"
     ]
    },
    {
     "data": {
      "text/plain": "Valutazione:   0%|          | 0/193 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "99e81c66ecb64270b5ce179996cb83b2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy CoOp (4-shot) sul TEST SET: 90.97%\n",
      "Differenza vs Zero-Shot: +19.68%\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Addestramento CoOp con 8 shot per classe ---\n"
     ]
    },
    {
     "data": {
      "text/plain": "Addestramento CoOp (8-shot):   0%|          | 0/200 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ae083fdc705d46aa86e3ff2516e147af"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Valutazione:   0%|          | 0/32 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b5305de8858540aa9c90e4b5b8f7350f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/200, Loss: 0.1196\n",
      "Validation Accuracy: 93.53%\n",
      " Nuovo modello migliore salvato in 'best_models/best_coop_8-shot.pth' con accuracy 93.53%\n"
     ]
    },
    {
     "data": {
      "text/plain": "Valutazione:   0%|          | 0/32 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "dcc84c842a4a49f4bc4719d28e4e4f71"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/200, Loss: 0.0505\n",
      "Validation Accuracy: 93.73%\n",
      " Nuovo modello migliore salvato in 'best_models/best_coop_8-shot.pth' con accuracy 93.73%\n"
     ]
    },
    {
     "data": {
      "text/plain": "Valutazione:   0%|          | 0/32 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "262ab6caf5484aaba4e73ef32d50175a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/200, Loss: 0.0304\n",
      "Validation Accuracy: 95.29%\n",
      " Nuovo modello migliore salvato in 'best_models/best_coop_8-shot.pth' con accuracy 95.29%\n"
     ]
    },
    {
     "data": {
      "text/plain": "Valutazione:   0%|          | 0/32 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "dd1372b54c12438ab103b213f9eaff63"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/200, Loss: 0.0229\n",
      "Validation Accuracy: 94.90%\n"
     ]
    },
    {
     "data": {
      "text/plain": "Valutazione:   0%|          | 0/32 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2b063d7e692a4cc3a0aef0d78154015c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/200, Loss: 0.0182\n",
      "Validation Accuracy: 94.90%\n"
     ]
    },
    {
     "data": {
      "text/plain": "Valutazione:   0%|          | 0/32 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d18cab9994ef469884d359fec60d32fd"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/200, Loss: 0.0150\n",
      "Validation Accuracy: 95.10%\n"
     ]
    },
    {
     "data": {
      "text/plain": "Valutazione:   0%|          | 0/32 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "663c7aac9d4a451d9ba48e4720b54fa3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70/200, Loss: 0.0129\n",
      "Validation Accuracy: 95.59%\n",
      " Nuovo modello migliore salvato in 'best_models/best_coop_8-shot.pth' con accuracy 95.59%\n"
     ]
    },
    {
     "data": {
      "text/plain": "Valutazione:   0%|          | 0/32 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e0360bdad39b46f995c05469dc17d83e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/200, Loss: 0.0113\n",
      "Validation Accuracy: 95.59%\n"
     ]
    },
    {
     "data": {
      "text/plain": "Valutazione:   0%|          | 0/32 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "986930ea467d441891ea3e0bb033d6fd"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90/200, Loss: 0.0103\n",
      "Validation Accuracy: 95.88%\n",
      " Nuovo modello migliore salvato in 'best_models/best_coop_8-shot.pth' con accuracy 95.88%\n"
     ]
    },
    {
     "data": {
      "text/plain": "Valutazione:   0%|          | 0/32 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "231f5412bf1046269026aec4881154a9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/200, Loss: 0.0094\n",
      "Validation Accuracy: 96.18%\n",
      " Nuovo modello migliore salvato in 'best_models/best_coop_8-shot.pth' con accuracy 96.18%\n"
     ]
    },
    {
     "data": {
      "text/plain": "Valutazione:   0%|          | 0/32 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "26daaeb128a34537b685de27b9d21204"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 110/200, Loss: 0.0087\n",
      "Validation Accuracy: 95.88%\n"
     ]
    },
    {
     "data": {
      "text/plain": "Valutazione:   0%|          | 0/32 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1a54b6bdd3534729b996a17998e0c5d1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 120/200, Loss: 0.0082\n",
      "Validation Accuracy: 95.98%\n"
     ]
    },
    {
     "data": {
      "text/plain": "Valutazione:   0%|          | 0/32 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b52989d828b24f0391472af68d3b70be"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 130/200, Loss: 0.0078\n",
      "Validation Accuracy: 96.08%\n"
     ]
    },
    {
     "data": {
      "text/plain": "Valutazione:   0%|          | 0/32 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d373dd75e3694625bd7f8417c14554d0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 140/200, Loss: 0.0075\n",
      "Validation Accuracy: 95.98%\n"
     ]
    },
    {
     "data": {
      "text/plain": "Valutazione:   0%|          | 0/32 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c9cf51cfa36341518ad9748aab21245f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 150/200, Loss: 0.0073\n",
      "Validation Accuracy: 95.88%\n"
     ]
    },
    {
     "data": {
      "text/plain": "Valutazione:   0%|          | 0/32 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9002ce4b72764ef39b87d2550bfccd96"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 160/200, Loss: 0.0071\n",
      "Validation Accuracy: 95.88%\n"
     ]
    },
    {
     "data": {
      "text/plain": "Valutazione:   0%|          | 0/32 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "106f3b88953c46a7a6ea3b988c210ba0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 170/200, Loss: 0.0070\n",
      "Validation Accuracy: 95.88%\n"
     ]
    },
    {
     "data": {
      "text/plain": "Valutazione:   0%|          | 0/32 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6f3a64c2dbe24b1b99ec7b8aed41e564"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 180/200, Loss: 0.0069\n",
      "Validation Accuracy: 95.88%\n"
     ]
    },
    {
     "data": {
      "text/plain": "Valutazione:   0%|          | 0/32 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "20405255815a41adb812b50b57cdae88"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 190/200, Loss: 0.0069\n",
      "Validation Accuracy: 95.88%\n"
     ]
    },
    {
     "data": {
      "text/plain": "Valutazione:   0%|          | 0/32 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "93206b5d031345ee9cdd220c004b1797"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 200/200, Loss: 0.0069\n",
      "Validation Accuracy: 95.88%\n"
     ]
    },
    {
     "data": {
      "text/plain": "Valutazione:   0%|          | 0/193 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1f2ed4bfd9d049b5af7d8412f96bd10c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy CoOp (8-shot) sul TEST SET: 95.14%\n",
      "Differenza vs Zero-Shot: +23.84%\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision.transforms import InterpolationMode, Resize, CenterCrop, ToTensor, Normalize, Compose\n",
    "from torchvision.datasets import Flowers102\n",
    "import os\n",
    "random.seed(10)\n",
    "SHOTS = [1, 2, 4, 8]\n",
    "M_CONTEXT_VECTORS = 16\n",
    "EPOCHS = [50,100,100,200] \n",
    "BATCH_SIZE = 4\n",
    "LEARNING_RATE = 2e-3\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "MODEL_NAME = \"openai/clip-vit-base-patch16\"\n",
    "\n",
    "processor = CLIPProcessor.from_pretrained(MODEL_NAME)\n",
    "if not os.path.exists(\"best_models\"):\n",
    "    os.makedirs(\"best_models\")\n",
    "\n",
    "\n",
    "#presa da https://github.com/openai/CLIP/blob/dcba3cb2e2827b402d2701e7e1c7d9fed8a20ef1/clip/clip.py#L79      \n",
    "def _convert_image_to_rgb(image):\n",
    "    return image.convert(\"RGB\")\n",
    "preprocess = Compose([\n",
    "        Resize(224, interpolation= InterpolationMode.BICUBIC),\n",
    "        CenterCrop(224),\n",
    "        _convert_image_to_rgb,\n",
    "        ToTensor(),\n",
    "        Normalize((0.48145466, 0.4578275, 0.40821073), (0.26862954, 0.26130258, 0.27577711)),\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "full_train_dataset = Flowers102(root=\"data\", split=\"train\", download=True, transform=preprocess)\n",
    "test_dataset = Flowers102(root=\"data\", split=\"test\", download=True, transform=preprocess)\n",
    "validation_dataset = Flowers102(root=\"data\", split=\"val\", download=True, transform=preprocess)\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, pin_memory=True)\n",
    "validation_loader = DataLoader(validation_dataset, batch_size=32, shuffle=False, pin_memory=True)\n",
    "\n",
    "base_clip_model = CLIPModel.from_pretrained(MODEL_NAME).to(DEVICE)\n",
    "\n",
    "print(f\"Caricato il dataset Flowers102 con {len(full_train_dataset)} immagini di addestramento, {len(test_dataset)} immagini di test e {len(validation_dataset)} immagini di validazione.\")\n",
    "\n",
    "class_names = full_train_dataset.classes\n",
    "\n",
    "\n",
    "\n",
    "def train_one_epoch(model, dataloader, optimizer, scheduler):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for images, labels in dataloader:\n",
    "        images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = nn.CrossEntropyLoss()(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        pbar.set_postfix({\"loss\": loss.item()})\n",
    "    scheduler.step()\n",
    "    return total_loss / len(dataloader)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\n--- Calcolo della Baseline Zero-Shot CLIP ---\")\n",
    "zeroshot_accuracy = evaluate(base_clip_model, test_loader, processor, class_names, is_zeroshot=True)\n",
    "print(f\"Accuracy Zero-Shot CLIP: {zeroshot_accuracy:.2f}%\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "results = {}    \n",
    "for i, shot in enumerate(SHOTS):\n",
    "    print(f\"\\n--- Addestramento CoOp con {shot} shot per classe ---\")\n",
    "    train_dataset_few_shot = create_few_shot_split(full_train_dataset, shot)\n",
    "    train_loader_few_shot = DataLoader(train_dataset_few_shot, batch_size=BATCH_SIZE, shuffle=True , pin_memory=True)\n",
    "\n",
    "    \n",
    "    coop_model = CoOpCLIP(class_names, base_clip_model, m_ctx=M_CONTEXT_VECTORS).to(DEVICE)\n",
    "    \n",
    "    optimizer = torch.optim.SGD(coop_model.parameters(), lr=LEARNING_RATE)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS[i])\n",
    "    \n",
    "    \n",
    "    best_val_accuracy = 0.0\n",
    "    best_model_path = f\"best_models/best_coop_{shot}-shot.pth\"\n",
    "    \n",
    "    \n",
    "    pbar = tqdm(range(EPOCHS[i]), desc=f\"Addestramento CoOp ({shot}-shot)\")\n",
    "    \n",
    "    for epoch in pbar:\n",
    "        train_loss = train_one_epoch(coop_model, train_loader_few_shot, optimizer, scheduler)\n",
    "        if (epoch+1) % 10 == 0:\n",
    "            coop_model.eval()\n",
    "            with torch.no_grad():\n",
    "                current_val_accuracy = evaluate(coop_model, validation_loader, processor, class_names)\n",
    "            print(f\"Epoch {epoch+1}/{EPOCHS[i]}, Loss: {train_loss:.4f}\")\n",
    "            print(f\"Validation Accuracy: {current_val_accuracy:.2f}%\")\n",
    "            if current_val_accuracy > best_val_accuracy:\n",
    "                best_val_accuracy = current_val_accuracy\n",
    "                torch.save(coop_model.state_dict(), best_model_path)\n",
    "                print(f\" Nuovo modello migliore salvato in '{best_model_path}' con accuracy {best_val_accuracy:.2f}%\")\n",
    "            \n",
    "            coop_model.train()\n",
    "    \n",
    "    \n",
    "    \n",
    "    coop_accuracy = evaluate(coop_model, test_loader, processor, class_names)\n",
    "    results[shot] = coop_accuracy\n",
    "    \n",
    "    print(f\"Accuracy CoOp ({shot}-shot) sul TEST SET: {coop_accuracy:.2f}%\")\n",
    "    print(f\"Differenza vs Zero-Shot: {coop_accuracy - zeroshot_accuracy:+.2f}%\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "138ac8e706bd89d1",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-07-02T16:35:12.844571100Z",
     "start_time": "2025-07-02T16:28:43.175445700Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "Valutazione:   0%|          | 0/193 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7f5ea50c716f4646b8e346bce42cfc31"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== RIEPILOGO DEI RISULTATI =====\n",
      "Baseline Zero-Shot CLIP: 71.30%\n",
      "-----------------------------------\n",
      "Shots\t| CoOp Accuracy\t| Miglioramento\n",
      "-----------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": "Valutazione:   0%|          | 0/193 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ec4db7a75c7e4e31b695daec8efc1bd9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\t| 77.52%\t\t| +6.23%\n"
     ]
    },
    {
     "data": {
      "text/plain": "Valutazione:   0%|          | 0/193 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bb233b92cca6442890758e9568186699"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\t| 89.35%\t\t| +18.05%\n"
     ]
    },
    {
     "data": {
      "text/plain": "Valutazione:   0%|          | 0/193 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fa96f8dcb3cb4d8d9c49ebc1e09e68bc"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\t| 90.97%\t\t| +19.68%\n"
     ]
    },
    {
     "data": {
      "text/plain": "Valutazione:   0%|          | 0/193 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "58a6aba3e419474a9cf43f1a92b4a47c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\t| 95.35%\t\t| +24.05%\n",
      "===================================\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 800x500 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.datasets import Flowers102\n",
    "from transformers import  CLIPModel, CLIPProcessor\n",
    "from torchvision.transforms import InterpolationMode, Resize, CenterCrop, ToTensor, Normalize, Compose\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "M_CONTEXT_VECTORS = 16\n",
    "SHOTS = [1, 2, 4, 8]\n",
    "def _convert_image_to_rgb(image):\n",
    "    return image.convert(\"RGB\")\n",
    "preprocess = Compose([\n",
    "    Resize(224, interpolation=InterpolationMode.BICUBIC),\n",
    "    CenterCrop(224),\n",
    "    _convert_image_to_rgb,\n",
    "    ToTensor(),\n",
    "    Normalize((0.48145466, 0.4578275, 0.40821073), (0.26862954, 0.26130258, 0.27577711)),\n",
    "])\n",
    "processor = CLIPProcessor.from_pretrained(MODEL_NAME)\n",
    "full_train_dataset = Flowers102(root=\"data\", split=\"train\", download=True, transform=preprocess)\n",
    "test_dataset = Flowers102(root=\"data\", split=\"test\", download=True, transform=preprocess)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, pin_memory=True)\n",
    "class_names = full_train_dataset.classes\n",
    "base_clip_model = CLIPModel.from_pretrained(MODEL_NAME).to(DEVICE)\n",
    "zeroshot_accuracy = evaluate(base_clip_model, test_loader, processor, class_names, is_zeroshot=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\n===== RIEPILOGO DEI RISULTATI =====\")\n",
    "print(f\"Baseline Zero-Shot CLIP: {zeroshot_accuracy:.2f}%\") \n",
    "print(\"-\" * 35)\n",
    "print(\"Shots\\t| CoOp Accuracy\\t| Miglioramento\")\n",
    "print(\"-\" * 35)\n",
    "results = {}\n",
    "for shot in SHOTS:\n",
    "    m = CoOpCLIP(class_names, base_clip_model, m_ctx=M_CONTEXT_VECTORS)\n",
    "    m.load_state_dict(torch.load(f\"best_models/best_coop_{shot}-shot.pth\"))\n",
    "    m.to(DEVICE)\n",
    "    m.eval()\n",
    "    with torch.no_grad():\n",
    "        acc = evaluate(m, test_loader, processor, class_names)\n",
    "    improvement = acc - zeroshot_accuracy\n",
    "    results[shot] = acc\n",
    "    print(f\"{shot}\\t| {acc:.2f}%\\t\\t| {improvement:+.2f}%\")\n",
    "print(\"=\" * 35)\n",
    "\n",
    "\n",
    "\n",
    "shots =  sorted(results.keys())\n",
    "accuracies =  [results[shot] for shot in sorted(results.keys())]\n",
    "plt.figure(figsize=(8, 5))\n",
    "\n",
    "plt.plot(shots, accuracies, marker='o', linestyle='-', color='blue', label='CoOp Accuracy')\n",
    "plt.scatter(0, zeroshot_accuracy, color='red', s=100, label='Zero-Shot CLIP', zorder=5)\n",
    "\n",
    "plt.title(\"Accuratezza in funzione degli Shot\")\n",
    "plt.xlabel(\"Numero di Shot\")\n",
    "plt.ylabel(\"Accuracy (%)\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
