Ho preso una implementazione del PPO e ho provato ad risolvere l'ambiente CarRacing-v3.
ho addestrato 4 modelli:
uno Vanilla PPO best_model_883.06_v.zip ( v sta per vanilla)
uno con un wrapper che modifica le reward in base alla velocità best_model_828.60_s.zip (s sta per speed)
uno con il wrapper che modifica le reward in a se si trova sul tracciato oppure no best_model_833.91_p.zip(p sta per penalty)
e infino uno che mette insieme entrambi i wrapper best_model_850.20_sp.zip (sp sta per speed + penalty)

nonostante i wrapper, il modello vanilla ha ottenuto il punteggio più alto.
Non sono riuscito a ottenere un miglioramento delle performance ma ho comunque modificato come si comporta il modello ad
esempio con il wrapper penalty il modello non taglia le curve, mentre con il wrapper speed il modello cerca di accelerare
di più.

l'allenalmento veninva interroto manualmente quando il modello non migliorava più.